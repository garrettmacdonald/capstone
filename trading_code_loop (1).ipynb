{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trading_code_loop.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# jupyter serverextension enable --py jupyter_http_over_ws\n",
        "# jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0"
      ],
      "metadata": {
        "id": "EoakIKv-jnAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import datetime\n",
        "import matplotlib as plt\n",
        "\n",
        "os.chdir('C:/Users/Garrett/Downloads/backtest_data')\n",
        "\n",
        "tickers = pd.read_csv('sp100.csv', names = ['ticker'], squeeze = True)\n",
        "\n",
        "tickers = tickers + '_5min.txt'"
      ],
      "metadata": {
        "id": "MNx-7UJLM5rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "d6flrvprEuun"
      },
      "outputs": [],
      "source": [
        "# get SPY\n",
        "header_list = ['datetime', 'open', 'high', 'low', 'close', 'volume']\n",
        "spy_df = pd.read_csv('SPY_5min.txt', names = header_list, index_col = 'datetime', parse_dates=True)\n",
        "\n",
        "# remove after-hours trading (before 9:30 AM and after 3:55 PM bars)\n",
        "spy_df_rth = spy_df.between_time('09:30:00', '15:55:00')\n",
        "\n",
        "# get daily closes\n",
        "spy_daily = spy_df.between_time('15:55:00', '15:55:00')['close']\n",
        "\n",
        "# get a vector of prior day closing prices\n",
        "spy_prior_close = spy_daily.reset_index()\n",
        "spy_prior_close['date'] = spy_prior_close['datetime'].dt.date\n",
        "spy_prior_close['date'] = spy_prior_close['date'].shift(-1)\n",
        "spy_prior_close.rename({'close': 'prior_close'}, axis=1, inplace=True)\n",
        "spy_prior_close.drop(columns=['datetime'], inplace=True)\n",
        "spy_prior_close.drop(spy_prior_close.tail(1).index,inplace=True)\n",
        "spy_prior_close = spy_prior_close[['date', 'prior_close']]\n",
        "\n",
        "# map the closing prices vector to each SPY 5m bar by date\n",
        "spy_df_datetime = spy_df_rth.reset_index()\n",
        "spy_df_datetime['date'] = spy_df_datetime['datetime'].dt.date\n",
        "spy_df_datetime = spy_df_datetime.merge(spy_prior_close, how='left', on='date')\n",
        "\n",
        "# subtract the prior day vector from the 5m closing price vector\n",
        "spy_df_datetime['spy_up_down'] = spy_df_datetime['close'] - spy_df_datetime['prior_close']\n",
        "\n",
        "# SPY ATR over last hour (twelve 5-min bars)\n",
        "spy_df_rth = spy_df_rth.reset_index()\n",
        "high_low = spy_df_rth['high'] - spy_df_rth['low']\n",
        "high_cp = np.abs(spy_df_rth['high'] - spy_df_rth['close'].shift())\n",
        "low_cp = np.abs(spy_df_rth['low'] - spy_df_rth['close'].shift())\n",
        "tr_df = pd.concat([high_low, high_cp, low_cp], axis=1)\n",
        "spy_true_range = np.max(tr_df, axis=1)\n",
        "spy_df_rth['spy_atr'] = spy_true_range.rolling(12).mean()\n",
        "spy_df_rth['power_index'] = (spy_df_rth['close'] - spy_df_rth['close'].shift(12)) / spy_df_rth['spy_atr']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vwap(df):\n",
        "    h = df.high.values\n",
        "    l = df.low.values\n",
        "    c = df.close.values\n",
        "    v = df.volume.values\n",
        "    return df.assign(vwap=((h+l+c)/3 * v).cumsum() / v.cumsum())"
      ],
      "metadata": {
        "id": "fNb40hD6GXW0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loop\n",
        "\n",
        "os.chdir('C:/Users/Garrett/Downloads/backtest_data/tickers')\n",
        "all_trades_df = pd.DataFrame(columns = ['Long/Short', 'Entry Datetime', 'Entry Price', 'Exit Datetime', 'Exit Price', 'PnL', 'Ticker'])\n",
        "\n",
        "# for ticker_file in tickers.head(1):\n",
        "for ticker_file in tickers:\n",
        "  print(ticker_file)\n",
        "  ticker_df = pd.read_csv(ticker_file, names = header_list, index_col = 'datetime', parse_dates=True)\n",
        "  ticker_df_rth = ticker_df.between_time('09:30:00', '15:55:00')\n",
        "\n",
        "  ticker_daily = ticker_df.between_time('15:55:00', '15:55:00')\n",
        "\n",
        "  pd.options.mode.chained_assignment = None\n",
        "  ticker_daily['sma20'] = ticker_daily['close'].rolling(window = 20, min_periods = 1).mean()\n",
        "  ticker_daily['sma50'] = ticker_daily['close'].rolling(window = 50, min_periods = 1).mean()\n",
        "  ticker_daily['sma100'] = ticker_daily['close'].rolling(window = 100, min_periods = 1).mean()\n",
        "  ticker_daily['sma200'] = ticker_daily['close'].rolling(window = 200, min_periods = 1).mean()\n",
        "  pd.options.mode.chained_assignment = 'warn'\n",
        "\n",
        "  ticker_daily = ticker_daily.reset_index()\n",
        "  ticker_daily['date'] = ticker_daily['datetime'].dt.date\n",
        "  ticker_daily['date'] = ticker_daily['date'].shift(-1)\n",
        "\n",
        "  # map the SMAs to the intraday prices\n",
        "  ticker_df_rth = ticker_df_rth.reset_index()\n",
        "  ticker_df_rth['date'] = ticker_df_rth['datetime'].dt.date\n",
        "\n",
        "  ticker_df_rth = ticker_df_rth.merge(ticker_daily[['date', 'sma20', 'sma50',\t'sma100',\t'sma200']], how='left', on='date')\n",
        "\n",
        "  # map the SPY up/down indicator to the 5m bars for the ticker\n",
        "  ticker_df_rth = ticker_df_rth.merge(spy_df_datetime[['datetime', 'spy_up_down']], how='left', on='datetime')\n",
        "\n",
        "  # calculate VWAP for ticker\n",
        "  ticker_df_rth.index = pd.to_datetime(ticker_df_rth.date)\n",
        "  ticker_df_rth = ticker_df_rth.groupby(ticker_df_rth.index.date, group_keys=False).apply(vwap)\n",
        "  ticker_df_rth['vwap'] = ticker_df_rth['vwap'].shift(1)\n",
        "\n",
        "  # ticker ATR over last hour\n",
        "  high_low = ticker_df_rth['high'] - ticker_df_rth['low']\n",
        "  high_cp = np.abs(ticker_df_rth['high'] - ticker_df_rth['close'].shift())\n",
        "  low_cp = np.abs(ticker_df_rth['low'] - ticker_df_rth['close'].shift())\n",
        "\n",
        "  tr_df = pd.concat([high_low, high_cp, low_cp], axis=1)\n",
        "  ticker_true_range = np.max(tr_df, axis=1)\n",
        "\n",
        "  ticker_df_rth['atr'] = ticker_true_range.rolling(12).mean()\n",
        "\n",
        "  # map SPY power index to ticker\n",
        "  ticker_df_rth = ticker_df_rth.merge(spy_df_rth[['datetime', 'power_index']], how='left', on='datetime')\n",
        "\n",
        "  # calculate relative strengh/weakness for ticker\n",
        "  ticker_df_rth['rsrw'] = (ticker_df_rth['close'] - ticker_df_rth['close'].shift(11)) / ticker_df_rth['atr'] - ticker_df_rth['power_index']\n",
        "\n",
        "  # cut out first 200 days to start with enough data for all SMAs\n",
        "  ticker_dates = ticker_df_rth['date'].unique()\n",
        "  ticker_df_rth = ticker_df_rth[ticker_df_rth['date'] >= ticker_dates[200]]\n",
        "\n",
        "  in_trade = 0\n",
        "  trades_df = pd.DataFrame(columns = ['Long/Short', 'Entry Datetime', 'Entry Price', 'Exit Datetime', 'Exit Price'])\n",
        "\n",
        "  for index, row in ticker_df_rth.iterrows():\n",
        "    # entries\n",
        "    if in_trade == 0 and row['datetime'].time() >= datetime.time(10, 30):\n",
        "      # if SPY is up and ticker is above all SMAs, VWAP, and has relative strength, go long\n",
        "      if row['spy_up_down'] > 0 and row['close'] > row['sma20'] and row['close'] > row['sma50'] and row['close'] > row['sma100'] and row['close'] > row['sma200'] and row['close'] > row['vwap'] and row['rsrw'] > 0:\n",
        "        in_trade = 1\n",
        "        entry_info = pd.DataFrame({'Long/Short': ['Long'], 'Entry Datetime': [ticker_df_rth['datetime'][index+1]], 'Entry Price': [ticker_df_rth['close'][index+1]]})\n",
        "        trades_df = pd.concat([trades_df, entry_info], ignore_index = True)\n",
        "      # if SPY is down and ticker is below all SMAs, VWAP, and has relative weakness, go short\n",
        "      elif row['spy_up_down'] < 0 and row['close'] < row['sma20'] and row['close'] < row['sma50'] and row['close'] < row['sma100'] and row['close'] < row['sma200'] and row['close'] < row['vwap'] and row['rsrw'] < 0:\n",
        "        in_trade = 1\n",
        "        entry_info = pd.DataFrame({'Long/Short': ['Short'], 'Entry Datetime': [ticker_df_rth['datetime'][index+1]], 'Entry Price': [ticker_df_rth['close'][index+1]]})\n",
        "        trades_df = pd.concat([trades_df, entry_info], ignore_index = True)\n",
        "    # exits\n",
        "    if in_trade == 1:\n",
        "      # if at least 4 of: long and SPY goes negative, ticker goes below VWAP or any SMA, or loses relative strength, close long\n",
        "      if trades_df.tail(1)['Long/Short'].item() == 'Long':\n",
        "        if (row['spy_up_down'] < 0) + (row['close'] < row['sma20']) +  \\\n",
        "        (row['close'] < row['sma50']) + (row['close'] < row['sma100']) + \\\n",
        "        (row['close'] < row['sma200']) + (row['close'] < row['vwap']) + (row['rsrw'] < 0) > 3:\n",
        "          in_trade = 0\n",
        "          trades_df.loc[trades_df.index[-1], 'Exit Datetime'] = ticker_df_rth['datetime'][index+1]\n",
        "          trades_df.loc[trades_df.index[-1], 'Exit Price'] = ticker_df_rth['close'][index+1]\n",
        "      # if at least 4 of: short and SPY goes positive, ticker goes above VWAP or any SMA, or loses relative weakness, close short\n",
        "      else:\n",
        "        if (row['spy_up_down'] > 0) + (row['close'] > row['sma20']) + \\\n",
        "      (row['close'] > row['sma50']) + (row['close'] > row['sma100']) + \\\n",
        "      (row['close'] > row['sma200']) + (row['close'] > row['vwap']) + (row['rsrw'] > 0) > 3:\n",
        "          in_trade = 0\n",
        "          trades_df.loc[trades_df.index[-1], 'Exit Datetime'] = ticker_df_rth['datetime'][index+1]\n",
        "          trades_df.loc[trades_df.index[-1], 'Exit Price'] = ticker_df_rth['close'][index+1]\n",
        "\n",
        "  # get PnL of trades\n",
        "  trades_df['PnL'] = trades_df['Exit Price'] / trades_df['Entry Price'] - 1\n",
        "\n",
        "  # reverse sign for shorts\n",
        "  trades_df.loc[trades_df['Long/Short'] == 'Short', 'PnL'] = trades_df.loc[trades_df['Long/Short'] == 'Short', 'PnL'] * -1\n",
        "\n",
        "  # if last trade is still open remove it\n",
        "  if np.isnan(trades_df.loc[trades_df.index[-1], 'PnL']) == True:\n",
        "    trades_df.drop(trades_df.tail(1).index,inplace=True)\n",
        "\n",
        "  # add to all trades\n",
        "  trades_df['Ticker'] = ticker_file\n",
        "  all_trades_df = pd.concat([all_trades_df, trades_df])\n",
        "\n",
        "# save all_trades_df\n",
        "os.chdir('C:/Users/Garrett/Downloads/backtest_data')\n",
        "all_trades_df.to_csv(path_or_buf='all_trades_df.csv')"
      ],
      "metadata": {
        "id": "l3CEpu2tFvuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stats\n",
        "print('number of trades: ', all_trades_df.shape[0])\n",
        "print('win rate: ', all_trades_df.loc[all_trades_df['PnL'] > 0].shape[0] / all_trades_df.shape[0])\n",
        "print('average win :', all_trades_df.loc[all_trades_df['PnL'] > 0, 'PnL'].mean())\n",
        "print('average loss :', all_trades_df.loc[all_trades_df['PnL'] < 0, 'PnL'].mean())\n",
        "print('total PnL :', (all_trades_df['PnL'] + 1).prod() - 1)\n",
        "print('win rate of longs: ', all_trades_df.loc[(all_trades_df['Long/Short'] == 'Long') & (all_trades_df['PnL'] > 0)].shape[0] / all_trades_df.loc[(all_trades_df['Long/Short'] == 'Long')].shape[0])\n",
        "print('win rate of shorts: ', all_trades_df.loc[(all_trades_df['Long/Short'] == 'Short') & (all_trades_df['PnL'] > 0)].shape[0] / all_trades_df.loc[(all_trades_df['Long/Short'] == 'Short')].shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inU6eP2d0QL5",
        "outputId": "0ad25b0f-c975-43f1-eb43-5f6f7d152011"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of trades:  44443\n",
            "win rate:  0.22232972571608578\n",
            "average win : 0.04086755380573609\n",
            "average loss : -0.010827632429652243\n",
            "total PnL : 3.9896499328523403\n",
            "win rate of longs:  0.24481892401088548\n",
            "win rate of shorts:  0.1814840631138711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_trades_df['PnL'].hist()"
      ],
      "metadata": {
        "id": "HrkzhJ3O2NYT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}